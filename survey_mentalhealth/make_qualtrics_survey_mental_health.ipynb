{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import re\n",
    "\n",
    "# Load the SME evaluations from the YAML file\n",
    "with open('../SME_Evaluations_MentalHealth.yaml', 'r') as file:\n",
    "    sme_evaluations = yaml.safe_load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# load_dotenv(find_dotenv())\n",
    "\n",
    "# from openai import OpenAI\n",
    "# import json\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# client = OpenAI()\n",
    "\n",
    "# # Load the SME evaluations from the YAML file\n",
    "# with open('sme-evaluations.yaml', 'r') as file:\n",
    "#     sme_evaluations = yaml.safe_load(file)\n",
    "\n",
    "# def generate(instruction, model=\"gpt-4o\"):\n",
    "#     completion = client.chat.completions.create(\n",
    "#         model=model,\n",
    "#         messages=[\n",
    "#             {\"role\": \"user\", \"content\": 'Does the following text contain any markdown? If so, replace it with simple html tags. Otherwise, leave it as is. Return as JSON with the key \"updated\" \\n\\n ```' + instruction + '```'}\n",
    "#         ],\n",
    "#         response_format={ \"type\": \"json_object\" }\n",
    "#     )\n",
    "#     return completion.choices[0].message.content\n",
    "\n",
    "# for x in tqdm(sme_evaluations['prompts']):\n",
    "#     response_1 = x['outputs'][0]\n",
    "#     response_2 = x['outputs'][1]\n",
    "#     response_1_fixed = generate(response_1)\n",
    "#     response_2_fixed = generate(response_2)\n",
    "#     x['outputs'][0] = response_1_fixed\n",
    "#     x['outputs'][1] = response_2_fixed\n",
    "#     x['updated_outputs'] = [json.loads(response_1_fixed)['updated'], json.loads(response_2_fixed)['updated']]\n",
    "\n",
    "# with open('updated-sme-evaluations.yaml', 'w') as file:\n",
    "#     yaml.dump(sme_evaluations, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../SME_Evaluations_MentalHealth.yaml', 'r') as file:\n",
    "    sme_evaluations = yaml.safe_load(file)\n",
    "\n",
    "# Read template files\n",
    "survey_template = open(\"qualtrics_survey_template.txt\").read()\n",
    "instruction_template = open(\"instruction_template.txt\").read()\n",
    "aspect_question_template = open(\"aspect_question_template.txt\").read()\n",
    "pre_interview_survey = open(\"pre_interview_survey.txt\").read()\n",
    "tutorial_page = open(\"tutorial_page.txt\").read()\n",
    "thank_you_page = open(\"thankyou_page.txt\").read()\n",
    "\n",
    "questions = []\n",
    "question_counter = 1\n",
    "\n",
    "for example in sme_evaluations['prompts']:\n",
    "    instruction = example['prompt']\n",
    "    instruction_id = f\"Q{question_counter}\"\n",
    "    \n",
    "    response_1 = example['outputs'][0]['text'].replace('\\n', '<br/>')\n",
    "    response_1_id = example['outputs'][0]['id']\n",
    "    \n",
    "    response_2 = example['outputs'][1]['text'].replace('\\n', '<br/>')\n",
    "    response_2_id = example['outputs'][1]['id']\n",
    "    \n",
    "    prompt_id = f\"Prompt{instruction_id}_a{response_1_id}_b{response_2_id}\"\n",
    "\n",
    "    aspect_questions = example['aspect_questions']\n",
    "    aspect_questions.insert(0, \"Which response is overall better?\")\n",
    "\n",
    "    filled_aspect_questions = []\n",
    "    question_label = ['a', 'b', 'c']\n",
    "\n",
    "    for idx, aq in enumerate(aspect_questions):\n",
    "        mc_question_id = f\"Q{question_counter}_{question_label[idx % len(question_label)]}\"\n",
    "        te_question_id = f\"T{question_counter}_{question_label[idx % len(question_label)]}\"\n",
    "        filled_aspect_questions.append(aspect_question_template.format(aspect_question=aq, mc_question_id=mc_question_id, te_question_id=te_question_id))\n",
    "\n",
    "    filled_aspect_questions_str = \"\\n\".join(filled_aspect_questions)\n",
    "\n",
    "    filled_instruction_str = instruction_template.format(\n",
    "        question_number=question_counter,\n",
    "        instruction_id=prompt_id,\n",
    "        instruction=instruction,\n",
    "        response_1=response_1,\n",
    "        response_2=response_2,\n",
    "        aspect_questions=filled_aspect_questions_str\n",
    "    )\n",
    "\n",
    "    questions.append(filled_instruction_str)\n",
    "    question_counter += 1\n",
    "\n",
    "questions_str = \"\\n\".join(questions)\n",
    "\n",
    "# Combine the consent form, pre-interview survey, and main questions\n",
    "full_survey = survey_template + \"\\n\" + pre_interview_survey + tutorial_page.format(questions=questions_str) + \"\\n\" + thank_you_page\n",
    "#print('\\n'.join(survey_str.split(\"\\n\")[:50]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey written to updated_qualtrics_survey.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"updated_qualtrics_survey_mental_health.txt\", \"w\") as file:\n",
    "    file.write(full_survey)\n",
    "    print(\"Survey written to updated_qualtrics_survey.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
